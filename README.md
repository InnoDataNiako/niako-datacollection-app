# ğŸ“Š Streamlit Data Collection - CoinAfrique

Ce projet est une application interactive dÃ©veloppÃ©e avec **Streamlit** pour scraper, explorer et visualiser des donnÃ©es issues du site **CoinAfrique**.

## Objectifs du projet

- Scraper les donnÃ©es de plusieurs catÃ©gories d'annonces (VÃªtements Homme, Chaussures Homme, VÃªtements Enfants, Chaussures Enfants) avec **BeautifulSoup**.
- TÃ©lÃ©charger des fichiers WebScraper (donnÃ©es non nettoyÃ©es).
- Afficher un dashboard interactif basÃ© sur les donnÃ©es nettoyÃ©es.
- IntÃ©grer un formulaire dâ€™Ã©valuation utilisateur.

## FonctionnalitÃ©s de l'app

- ğŸ”„ **Scraping via BeautifulSoup** : SÃ©lection de catÃ©gorie et nombre de pages Ã  scraper.
- ğŸ“¥ **TÃ©lÃ©chargement WebScraper** : DonnÃ©es rÃ©cupÃ©rÃ©es via lâ€™extension WebScraper.io (non nettoyÃ©es).
- ğŸ“Š **Dashboard dynamique** : Visualisation des donnÃ©es nettoyÃ©es sous forme de KPI, graphiques, analyses par ville et par type.
- ğŸ“ **Formulaire dâ€™Ã©valuation** : Pour recueillir des retours utilisateurs.

## Technologies utilisÃ©es

- Python
- Streamlit
- BeautifulSoup
- Pandas
- Plotly
- WebScraper
- Git/GitHub

## Lancer l'application localement

1. Cloner le dÃ©pÃ´t :
```bash
git clone https://github.com/InnoDataNiako/first_app_streamlit_datacollection.git
cd first_app_streamlit_datacollection
```

2. Installer les dÃ©pendances :

```bash
pip install -r requirements.txt
```

3. Lancer l'application :

```bash
streamlit run app.py
```

---

## DÃ©ploiement

L'application peut Ãªtre dÃ©ployÃ©e facilement sur **Streamlit Community Cloud** ou tout autre service compatible.

Lien de l'app dÃ©ployÃ©e : *https://niako-datacollection-app.streamlit.app/*

---

## Structure du projet

```
ğŸ“¦ niako-datacollection-app
â”‚
â”œâ”€â”€ app.py                       # Fichier principal Streamlit
â”œâ”€â”€ scraping/                    # Contient le code de scraping BeautifulSoup
â”‚   â””â”€â”€ scraper_4url_BS.py
â”œâ”€â”€ webscraper_data/             # DonnÃ©es issues de WebScraper
â”œâ”€â”€ cleaned_data/                # DonnÃ©es nettoyÃ©es
â”œâ”€â”€ README.md                    # Ce fichier
â””â”€â”€ requirements.txt             # DÃ©pendances Python
```

---

## Auteur

**Niako Kebe**  
Ã‰tudiante passionnÃ©e de data science & dÃ©veloppement.  
ğŸ“§ Contact : [drivenindata@gmail.com](mailto:drivenindata@gmail.com)

---

## Remarques

* Le scraping peut prendre quelques minutes selon le nombre de pages choisies.
* Assurez-vous dâ€™avoir une connexion internet pour accÃ©der aux URLs du site.

---