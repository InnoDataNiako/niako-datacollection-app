

# ğŸ“Š Streamlit Data Collection - Expat Dakar

Ce projet est une application interactive dÃ©veloppÃ©e avec **Streamlit** pour scraper, explorer et visualiser des donnÃ©es 


##  Objectifs du projet

- Scraper les donnÃ©es de plusieurs catÃ©gories d'annonces (RÃ©frigÃ©rateurs, Climatisations, Fours, Machines Ã  laver) avec **Selenium**.
- TÃ©lÃ©charger des fichiers WebScraper (donnÃ©es non nettoyÃ©es).
- Afficher un dashboard interactif basÃ© sur les donnÃ©es nettoyÃ©es.
- IntÃ©grer un formulaire dâ€™Ã©valuation utilisateur.


##  FonctionnalitÃ©s de l'app

- ğŸ”„ **Scraping via Selenium** : SÃ©lection de catÃ©gorie et nombre de pages Ã  scraper.
- ğŸ“¥ **TÃ©lÃ©chargement WebScraper** : DonnÃ©es rÃ©cupÃ©rÃ©es via lâ€™extension WebScraper.io (non nettoyÃ©es).
- ğŸ“Š **Dashboard dynamique** : Visualisation des donnÃ©es nettoyÃ©es sous forme de KPI, graphiques, analyses par ville et par marque.
- ğŸ“ **Formulaire dâ€™Ã©valuation** : Pour recueillir des retours utilisateurs.


##  Technologies utilisÃ©es

- Python
- Streamlit
- Selenium
- Pandas
- Plotly
- WebScraper
- Git/GitHub


##  Lancer l'application localement

1. Cloner le dÃ©pÃ´t :
git clone https://github.com/InnoDataNiako/first_app_streamlit_datacollection.git
cd first_app_streamlit_datacollection

2. Installer les dÃ©pendances :

```bash
pip install -r requirements.txt
```

3. Lancer l'application :

```bash
streamlit run app.py
```

---

##  DÃ©ploiement

L'application peut Ãªtre dÃ©ployÃ©e facilement sur **Streamlit Community Cloud** ou tout autre service compatible.

Lien de l'app dÃ©ployÃ©e : *(Ã  insÃ©rer aprÃ¨s dÃ©ploiement)*

---

##  Structure du projet

```
ğŸ“¦ first_app_streamlit_datacollection
â”‚
â”œâ”€â”€ app.py                       # Fichier principal Streamlit
â”œâ”€â”€ scraping/                   # Contient le code de scraping Selenium
â”‚   â””â”€â”€ scraper_selenium.py
â”œâ”€â”€ webscraper_data/            # DonnÃ©es issues de WebScraper
â”œâ”€â”€ cleaned_data/               # DonnÃ©es nettoyÃ©es
â”œâ”€â”€ README.md                   # Ce fichier
â””â”€â”€ requirements.txt            # DÃ©pendances Python
```

---

##  Auteur

**Niako Kebe**
Ã‰tudiante passionnÃ©e de data science & dÃ©veloppement.
ğŸ“§ Contact : [drivenindata@gmail.com](mailto:drivenindata@gmail.com)

---

##  Remarques

* Le scraping peut prendre quelques minutes selon le nombre de pages choisies.
* Assurez-vous dâ€™avoir une connexion internet pour accÃ©der aux URLs du site.

---
